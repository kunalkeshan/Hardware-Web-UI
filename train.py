# -*- coding: utf-8 -*-
"""pynq2-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jwiDrq87wfV3nMsukoKu_11hNLfNUgUn

# This program was run on 16000 images with 0.5 dropout and sigmoid activation

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import keras

import cv2
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import keras
import cv2
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense

# from google.colab import drive
# drive.mount('/content/drive')

img_size = 224
batch_size = 64
channel = 3

dataset = tf.keras.preprocessing.image_dataset_from_directory('./birads',
                                                             shuffle= True,
                                                             seed = 42,
                                                             image_size=(img_size,img_size),
                                                             batch_size= batch_size,
                                                              color_mode = "rgb")

class_name = dataset.class_names
class_name

for img_batch, label_batch in dataset.take(1):
    plt.imshow(img_batch[1].numpy().astype("uint8"))
    plt.title(class_name[label_batch[1]])
    plt.axis("Off")

print("Number of batches in a Dataset:", len(dataset))

# Taking 80% of data for training purpose
train_ds = dataset.take(round(len(dataset)* 0.9))

# Skipping 80% of training data and Taking remaining 20% of data for Validation and Test
val_n_test = dataset.skip(round(len(dataset)*0.1))

# Taking 10% of data from val_n_test for validation and another 10% for test data
val_ds = val_n_test.take(round(len(val_n_test)*0.5))
test_ds = val_n_test.skip(round(len(val_n_test)*0.5))

print("Train Dataset:",len(train_ds))
print()
print("Number of batches selected for test and validation:", len(val_n_test))
print("Validation Dataset:",len(val_ds))
print("Test Dataset:", len(test_ds))

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size= tf.data.AUTOTUNE)
test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size= tf.data.AUTOTUNE)
val_ds  = val_ds.cache().shuffle(1000).prefetch(buffer_size= tf.data.AUTOTUNE)

model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=(img_size,img_size, channel)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())  
model.add(Dense(128))
model.add(Dense(64))

model.add(Activation('relu'))

#model.add(Dropout(0.1))
model.add(Dense(5))
model.add(Activation('sigmoid'))
optimizer=tf.keras.optimizers.Adam (lr=0.0000999)


model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              optimizer=optimizer,
              metrics=['accuracy'])

model.summary()

history = model.fit(train_ds,
          batch_size = batch_size,
          validation_data = val_ds,
          verbose=1,
          epochs=40,)

scores = model.evaluate(test_ds)

scores

history.params

history.history.keys()

loss = history.history["loss"]
acc = history.history["accuracy"]

val_loss = history.history["val_loss"]
val_acc = history.history["val_accuracy"]

plt.figure(figsize=(12,6))
plt.subplot(1,2,1)
plt.plot(range(40), acc, label="Accuracy")
plt.plot(range(40), val_acc, label="Validation Accuracy")
plt.legend(loc="lower right")
plt.title("Training and Validation Accuracy")


plt.subplot(1,2,2)
plt.plot(range(40), loss, label="Loss")
plt.plot(range(40), val_loss,label="Validation_Loss")
plt.legend(loc="upper right")
plt.title("Loss and Validation Loss")
plt.show()

model.save("./trained.h5")

test_loss, test_acc = model.evaluate(test_ds, verbose=2)
print("\nTestAccuracy:", test_acc)

# new_model = keras.models.load_model("/trained.h5")

# for img,label in test_ds.take(200):
#   prediction = model.predict(img)
#   print(class_name[np.argmin(prediction[0])])
#   print(f"Accuracy Score: {round(np.max(prediction[0]),2)}")
#   plt.imshow(img[0].numpy().astype("uint8"))
#   plt.axis("off")
#   break

# from keras.models import load_model
# import cv2
# import numpy as np

# model=load_model('pynq2.h5')

# img = cv2.imread('/content/drive/MyDrive/Train/srm/Case15-100001.jpg')
# plt.imshow(img)
# plt.show()

# img = cv2.imread('/content/drive/MyDrive/Train/srm/Case13-100001.jpg')
# plt.imshow(img)
# plt.show()
# img = cv2.resize(img,(224,224))
# img = np.reshape(img,[1,224,224,3])
# prediction = model.predict(img)
# print (class_name[np.argmax(prediction[0])])
# print (f"Accuracy score: {round(np.max(prediction[0]),2)}")
# print (f"case12:2067687 -RCC")

# Birad=3
# if(Birad==1):
#     print(" BI-RADS 1,\n  *no finding is present in an imaging modality (not even a benign finding),\n  *there is nothing to comment on,\n  *a normal examination\n")
# elif(Birad==2):
#   print("BI-RADS 2 is a benign category,\n  *A finding placed in this category should have a 100% chance of being benign,\n *The lesion can be one among the following,\n calcified fibroadenomas,\n multiple secretory calcifications,\n fat-containing lesions such as\n oil cysts,\n breast lipomas,\n galactoceles,\n mixed density hamartomas,\n cutaneous neurofibromas, \n intramammary lymph nodes,\n breast sebaceous cysts,\n simple breast cysts,\n breast implants")
# elif(Birad==3):
#   print("BI-RADS 3,\n  *A finding placed in this category is considered probably benign,\n  *With a risk of malignancy of > 0% and â‰¤ 2%4,\n  *Grouped round calcifications,\n  *Circumscribed, round or oval mass without calcification,\n  *Focal asymmetry without calcification or architectural distortion\n")
# elif(Birad==4):
#     print(" BI-RADS 4,\n *Suspicious for malignancy with 2-94% probability of malignancy,\n *BI-RADS 4 lesions may not have the characteristic morphology of breast cancer but have a definite probability of being malignant,\n *A biopsy is recommended for these lesions\n")
# else:
#     print("BI-RADS 5,\n  *Malignant spiculated or irregular mass,\n  *High density,\n  *Fine linear or linear branching segmental calcifications\n")